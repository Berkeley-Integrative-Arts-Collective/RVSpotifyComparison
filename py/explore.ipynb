{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis file for Spotify Comparison\n",
    "$\\copyright$ Gaurav Bhatnagar gbhatnagar@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Imports, cleaning of data, and utility definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass, field\n",
    "from typing import *\n",
    "from pprint import pprint\n",
    "import jsons\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up and parsing of data\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials())\n",
    "\n",
    "df = pd.read_csv('../resources/bubbleflexe-rv.csv', usecols=[1, 2], names=['bsides', 'tt'])\n",
    "df = df.dropna()\n",
    "df = df.drop(labels=0, axis=0).reset_index(drop=True)\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].apply(lambda x: str(x).split(';'))\n",
    "# unify the responded songs\n",
    "df['unified'] = df['bsides'] + df['tt']\n",
    "\n",
    "df.to_csv('export/responses_frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def dictionaryFilter(d: dict, func) -> dict:\n",
    "    '''Filter a dictionary d by items that result in true for func(k, v)'''\n",
    "    return {k: v for k, v in d.items() if func(k, v)}\n",
    "\n",
    "unique_bsides = set()\n",
    "for i in df['bsides']:\n",
    "    unique_bsides.update(i)\n",
    "\n",
    "unique_tt = set()\n",
    "for i in df['tt']:\n",
    "    unique_tt.update(i)\n",
    "\n",
    "unique_songs = unique_bsides.union(unique_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAR: No NaNs detected\n"
     ]
    }
   ],
   "source": [
    "# N=5,700 after cleaning non-responses (nans)\n",
    "# note that there is no response where they gave favorite b-sides and no tt's, vice versa -- all nans in dataframe can be cleaned naively\n",
    "# Verify no nans\n",
    "count = 0\n",
    "for x in df['unified']:\n",
    "    if 'nan' in x:\n",
    "        print(x)\n",
    "        count+=1\n",
    "if count:\n",
    "    print('NaNs deteced')\n",
    "else:\n",
    "    print('CLEAR: No NaNs detected')\n",
    "\n",
    "# TODO report stats on responses (e.g. dist of responses of b-sides, tt's, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving Questions\n",
    "We're interested in understanding the relationship between songs across some attributes. For us, we have a list of responses of people's favorite Red Velvet songs, and we want to see how that measures up against Spotify's audio features of a song (how \"dark\" is the song? how \"danceable\" is the song? etc). Let's think about how we can represent the responses.\n",
    "\n",
    "Let's cover the most basic notion of popularity. Consider that each song has a number of users that listen to it. If we list all the songs based on how many users listen to them, we get something we will call the \"count list\".\n",
    "\n",
    "For each song, we want to be able to find which songs are \"connected\" to it. Given all the responses containing that song, we can tally up which other songs they listen to. Thus, if we make a list of all the other songs and how many times they were mentioned across the responses, we get something we will call the \"song count list\". For the mathematical framework, let's include the song we are talking about inside of its own song count list -- naturally, this value is then equal it's value in the \"count list\". The song count list is a very loose sense of seeing which songs are \"connected\" to one another.\n",
    "\n",
    "What if want to think about the likelihood of a listener of Psycho to listen to Bad Boy, or any other song? We can take the song count list of Psycho and divide the value of each song by the total number of Psycho listeners. If 900 people listen to Psycho, and 500 listen to both Psycho and Bad Boy, we can say 5/9 of Psycho listeners listen to Bad Boy. We call this list the \"outbound list\" for a song.\n",
    "\n",
    "There's also an inbound list, which is the % of Bad Boy or any other song's listeners that also listen to Psycho. Take the song count list of Psycho and divide each song by it's value in the count list. If 9000 people listen to Psycho, 500 listen to both Psycho and Bad Boy, and 800 people listen to Bad Boy, 5/8 of Bad Boy listeners listen to Psycho.\n",
    "\n",
    "Inbound lists (and/or outbound lists -- you can think about this more or see the next section) form a directed weighted graph over all the songs that we can analyze!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Framework\n",
    "For easier communication, we will follow a framework when discussing the project. There are more potential definitions for when we complete the network analysis.\n",
    "\n",
    "### Canonical objects\n",
    "These are the objects that are from the data. We construct other objects around these two objects.\n",
    "\n",
    "The set of all songs is $S$ and an individual song is $s_i$. WLOG we have $i \\in \\mathbb{N}$. We call this `songs` in the code. \n",
    "\n",
    "Consider the responses $R$ as a vector of subsets of Songs (i.e.  each individual response $r_i \\subseteq S$ is an element of $R$). This is `df['unified']` in the code. We don't currently make a distinction between title tracks and b-sides, so we unify the responses together. (Sidenote: when I first wrote this I erroneously wrote that $R$ is subset of the powerset of S -- this isn't true because we could have duplicate responses that we want to keep!)\n",
    "\n",
    "### Constructed objects\n",
    "We define a $|S| \\times |S|$ matrix $M$ such that $M_{ij} = \\sum_{r \\in R} \\mathbf{1}_{\\{s_i, s_j\\} \\subseteq r}$. In English, $M_\\text{Psycho, Bad Boy}$ would be equal to the number of responses in which Psycho and Bad Boy were both included. Fun fact, $M$ is symmetric, and $M_i,i$ is equal to the number of times $s_i$ was mentioned in the responses. We use the pandas dataframe `sdf` (song dataframe) to represent this. \n",
    "\n",
    "Note that the song count list (let's call it $C_{s_i}$) is equal to a row (or column) of $M$, i.e. $C_{s_i}=M_{i,}=M_{,j}$. We can calculate the outbound list (let's call it $O_{s_i}$) by taking $\\frac{C_{s_i}}{diag(M)[i]}$. The inbound list is not particularly important for the analysis (consider that the set of all inbound edges and all outbound edges are actually equal when taken over all responses and songs due to inbound and outbound edges being decompositions of the undirected edges, use handshake lemma) but can be found by doing elementwise division of the song count list and the diagonal of $M$.\n",
    "\n",
    "You can consider $M$ to be the adjacency matrix representation of an undirected, weighted, and complete graph $G_m = \\{V_m, E_m\\}$ where $V_m = S$ and $E_m = \\{\\{s_i, s_j\\}, M_{ij} | \\forall i, j \\leq |S|\\}$. This is a graph of songs where songs are connected by an weighted edge equalling the number of times those two songs were in a response together (over all responses).\n",
    "\n",
    "Consider a $|S| \\times |S|$ matrix $P$ such that $P_{ij}$ is the proportion of listeners of $s_i$ that also listen to $s_j$. Note that each row of $P$ is just the outbound list for a song $s_i$. It similarly forms a directed, weighted graph $G_p$. In terms of a Markov Chain, you can think of $P_{ij}$ to be the transition probability from $s_i$ to $s_j$. We can easily get the inbound list by taking a column of $P$ for a song $s_i$. \n",
    "\n",
    "Finally, with $P$ and $G_p$, this is where we can get a big chunk of our analysis: they represent how \"connected\" songs are to one another! . If $|P_\\text{Psycho, Bad Boy} - P_\\text{Bad Boy, Psycho}| < \\delta$ for some small $\\delta$, we can say the songs are equally popular TO one another. There's a lot more analysis of these that we need to do... which is a job to discuss on our call!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "A `Song` object represents a song $s_i$ and fetches audio features about it from Spotify, accesible via the object variable `spotify_af`. If you have `Song`s as the key in a dictionary, you can access it by using the name of the song as a string. Likewise you can directly check `'Psycho' in songs` where `songs` is a a `List[Song]` of all RV songs. It's hash is the name of the song, so we will get collisions if we are working with 2 of the same titled songs -- since we are only working with one artist, this never occurs and is safe. This functionality makes working with `SongCollection` and `Song`s much easier, but is an imperfect solution.\n",
    "\n",
    "A `SongCollection` object represents a set of songs with statistics about the responses. Within the framework, it's effectively a tuple of $S$, $R$, and $M$ and outputs $C_{s_i}$ and rows of $P$. For all public functions of `SongCollection`, you can refer to a song by it's string name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song:\n",
    "    # todo make init based on name and artist make a spotify req to populate the object's name and artist\n",
    "    def __init__(self, name: str, artist: str = 'Red Velvet', id: str = None, spotify_af: dict = None, tags: list = None):\n",
    "        self.name = name\n",
    "        self.artist = artist\n",
    "        self.id = id or self.__get_track_id()\n",
    "        self.spotify_af = spotify_af or self.__get_audio_analysis()\n",
    "        self.tags = tags\n",
    "    \n",
    "    def __get_track_id(self):\n",
    "        r = spotify.search(q=f'{self.name} artist:{self.artist}', type='track')\n",
    "        return r['tracks']['items'][0]['id']\n",
    "    \n",
    "    def __get_audio_analysis(self):\n",
    "        ft = spotify.audio_features(self.id)[0]\n",
    "        delkeys = ['type', 'id', 'uri', 'track_href', 'analysis_url']\n",
    "        [ft.pop(x) for x in delkeys]\n",
    "        return ft\n",
    "\n",
    "    def __repr__(self):\n",
    "        # TODO see if this is safe\n",
    "        return f'{self.name} - {self.artist} - {str(self.tags)}'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.name} - {self.artist} - [{str(self.tags)}]'\n",
    "\n",
    "    def __key(self):\n",
    "        return (self.name) # TODO THIS IS ONLY DUE TO WORKING WITH RV CONTENT.\n",
    "        # TODO find out a better way to make SongCollection like a dictionary but with regex matching for song name; make easier to extract from responses\n",
    "\n",
    "    def __hash__(self):\n",
    "        # note that we are heavily breaking convention here\n",
    "        return hash(self.__key())\n",
    "\n",
    "    def __eq__(self, o):\n",
    "        if isinstance(o, Song):\n",
    "            # if self.name == o.name and self.artist == o.artist:\n",
    "            #     return True\n",
    "            return self.__key() == o.__key()\n",
    "        elif isinstance(o, str):\n",
    "            # this is more useful for when there are multiple artists. we are only working with RV songs, so it's looser\n",
    "            # if o == str(self)[:str(self).rfind('-')-1]:\n",
    "            #     return True\n",
    "            if o.lower() == self.name.lower():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "@dataclass\n",
    "class SongCollection:\n",
    "    songs: List[Song]\n",
    "    responses: pd.DataFrame\n",
    "    count_adj_mat: pd.DataFrame\n",
    "    count_list: pd.Series = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.count_list = self.__get_count_list()\n",
    "            \n",
    "    def get(self, match) -> Song:\n",
    "        '''Return matching Song object for query'''\n",
    "        # TODO add this to the run attr of the class for methods that have a parameter songmatch. Advanced!\n",
    "        if isinstance(match, Song):\n",
    "            if match not in self.songs:\n",
    "                raise Exception('Song object provided is not in the SongCollection\\'s songs')\n",
    "            return match\n",
    "        return self.__get_handler(self.__get_by_name, match)\n",
    "\n",
    "    def __get_handler(self, method, match):\n",
    "        '''Wrapper method for handling output of searching by method with query match'''\n",
    "        r = method(match)\n",
    "        if len(r) > 1:\n",
    "            raise Exception('too many songs matched')\n",
    "        elif len(r) == 0:\n",
    "            raise Exception('no matching Song found')\n",
    "        return r[0]\n",
    "\n",
    "    def __get_by_name(self, name):\n",
    "        name = name.lower()\n",
    "        return [s for s in self.songs if s.name.lower() == name]\n",
    "        # r = list(filter(lambda s: s.name.lower() == name, self.songs))\n",
    "\n",
    "    def __get_by_eq(self, obj):\n",
    "        return [s for s in self.songs if s == obj]\n",
    "\n",
    "\n",
    "    def __get_count_list(self) -> pd.Series:\n",
    "        '''Return sorted series representing # of times a Song was mentioned in responses for all Songs in the collection'''\n",
    "        # this is equivalent to the diagonal in the adj matrix\n",
    "        return pd.Series(np.diag(self.count_adj_mat), index=songs).sort_values()\n",
    "        \n",
    "    def get_song_count_list(self, songmatch) -> pd.Series:\n",
    "        '''Return sorted series of the count of other songs in the responses for a given Song (det. by songmatch)'''\n",
    "        # this is requivallent to a row or column\n",
    "        song = self.get(songmatch)\n",
    "        return self.count_adj_mat[song].sort_values()\n",
    "\n",
    "    def get_song_inbound_percent_list(self, songmatch, dig=2) -> pd.Series:\n",
    "        '''\n",
    "        Return the inbound percents for a song. \n",
    "        i.e. for each Song s in a given Song t's count list, divide s's value in t's count list by the count of s in the responses\n",
    "        This gives us a way to see the percent of s's listeners that listen to t.\n",
    "        '''\n",
    "        song = self.get(songmatch)\n",
    "        return (self.count_adj_mat[song]/self.count_list).round(decimals=dig).sort_values() # series division\n",
    "\n",
    "    def get_song_outbound_percent_list(self, songmatch, dig=2) -> pd.Series:\n",
    "        '''\n",
    "        Return the outbound percents for a song\n",
    "        i.e. for each Song s in a given Song t's count list, divide s's value in t's count list by the count of t in the responses\n",
    "        This gives us a way to see the percent of t's listeners that listen to s.\n",
    "        '''\n",
    "        song = self.get(songmatch)\n",
    "        return (self.count_adj_mat[song]/self.count_list[song]).round(decimals=dig).sort_values()\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = [Song(name) for name in unique_songs]\n",
    "with open('export/songs', 'w') as f:\n",
    "    f.write(jsons.dumps(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('export/songs', 'r') as f:\n",
    "    songs = jsons.loads(f.read(), List[Song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.DataFrame(0, index=songs, columns=songs)\n",
    "def handleResponse(resp: List):\n",
    "    '''Recursively handle a response and add it to the song dataframe'''\n",
    "    if not len(resp):\n",
    "        return\n",
    "    last_song: str = resp.pop()\n",
    "    sdf.at[last_song, last_song] += 1\n",
    "    for song in resp:\n",
    "        sdf.at[last_song, song] += 1\n",
    "        sdf.at[song, last_song] += 1\n",
    "    handleResponse(resp)\n",
    "\n",
    "for r in df['unified']:\n",
    "    handleResponse(r.copy())\n",
    "\n",
    "sdf.to_csv('export/song_adj_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.read_csv('export/song_adj_mat.csv', index_col=0, header=0).set_axis(songs, axis=0).set_axis(songs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Milkshake - Red Velvet - [None]                   1606\n",
       "Cool World - Red Velvet - [None]                   472\n",
       "'Cause It's You - Red Velvet - [None]              442\n",
       "Lady's Room - Red Velvet - [None]                  373\n",
       "Eyes Locked Hands Locked - Red Velvet - [None]     911\n",
       "                                                  ... \n",
       "Look - Red Velvet - [None]                         979\n",
       "Little Little - Red Velvet - [None]                724\n",
       "Somethin Kinda Crazy - Red Velvet - [None]         532\n",
       "Moonlight Melody - Red Velvet - [None]             674\n",
       "RBB - Red Velvet - [None]                         1056\n",
       "Name: Milkshake - Red Velvet - [None], Length: 92, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf['Milkshake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = SongCollection(songs, df, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First Time - Red Velvet - [None]           0.11\n",
       "Rose Scent Breeze - Red Velvet - [None]    0.12\n",
       "Stupid Cupid - Red Velvet - [None]         0.12\n",
       "My Dear - Red Velvet - [None]              0.12\n",
       "Lady's Room - Red Velvet - [None]          0.13\n",
       "                                           ... \n",
       "In & Out - Red Velvet - [None]             0.65\n",
       "Kingdom Come - Red Velvet - [None]         0.65\n",
       "Peek-A-Boo - Red Velvet - [None]           0.66\n",
       "Bad Boy - Red Velvet - [None]              0.79\n",
       "Psycho - Red Velvet - [None]               1.00\n",
       "Name: Psycho - Red Velvet - [None], Length: 92, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.get_song_outbound_percent_list('Psycho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de/serialization doesn't work on col\n",
    "\n",
    "# with open('export/songcol.json', 'w') as f:\n",
    "#     f.write(jsons.dumps(col))\n",
    "\n",
    "# with open('export/songcol.json', 'r') as f:\n",
    "#     col = jsons.loads(f.read(), SongCollection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing, Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions on dataset\n",
    "* Which songs have high mutual connectivity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectionStatistics:\n",
    "    def __init__(self, col: SongCollection):\n",
    "        self.col = col\n",
    "    \n",
    "    def get_mutual_pairs(self, cutoff=0.5, attr=None, attr_filter=None):\n",
    "        '''Return all edges that satisfy the '''\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01667ff299c348b112dbc2df39ce92b4c0671ba931181a61d0cfac5f7a112035"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
